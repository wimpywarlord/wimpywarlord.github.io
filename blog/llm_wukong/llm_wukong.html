<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>BLOG_TITLE - Tjay</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Display:ital,wght@0,100..900;1,100..900&display=swap"
    rel="stylesheet">

    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="How to make an LLM play Black Myth: Wukong" />
    <meta property="og:description" content="A deep dive into building agentic LLMs for real-time game control, latency optimizations, and more." />
    <meta property="og:image" content="https://kshitijdhyani.com/assets/meow_party.gif" />
    <meta property="og:url" content="https://kshitijdhyani.com/blog/llm_wukong/llm_wukong.html" />
    <meta property="og:type" content="article" />

    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="How to make an LLM play Black Myth: Wukong" />
    <meta name="twitter:description" content="A deep dive into building agentic LLMs for real-time game control, latency optimizations, and more." />
    <meta name="twitter:image" content="https://kshitijdhyani.com/assets/meow_party.gif" />

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="https://kshitijdhyani.com/assets/meow_party.gif" />

  <style>
    /* Base styles matching main site */
    body {
      font-family: "Noto Sans Display", sans-serif;
      background-color: #282a36;
      color: #f8f8f2;
      line-height: 1.6;
      margin: 0;
      padding: 0;
    }

    /* Reset link styles */
    a {
      color: inherit;
      text-decoration: none;
    }

    a:hover,
    a:focus-visible {
      text-decoration: underline;
    }

    /* Container */
    .container {
      max-width: 800px;
      margin: 0 auto;
      padding: 2rem;
    }

    /* Navigation */
    .back-link {
      display: inline-flex;
      align-items: center;
      font-size: 0.9rem;
      color: #6272a4;
      margin-bottom: 2rem;
      transition: color 0.15s;
    }

    .back-link:hover {
      color: #f8f8f2;
    }

    /* Blog post styles */
    .blog-post {
      max-width: 700px;
      margin: 0 auto;
    }

    .post-header {
      margin-bottom: 3rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid #44475a;
    }

    .post-meta {
      display: flex;
      align-items: center;
      gap: 1rem;
      margin-bottom: 0.5rem;
    }

    .post-date {
      font-size: 0.85rem;
      color: #6272a4;
      font-family: ui-monospace, SFMono-Regular, Menlo, monospace;
    }

    .post-status {
      font-size: 0.75rem;
      background: #44475a;
      padding: 0.15rem 0.45rem;
      border-radius: 0.25rem;
      color: #ffb86c;
      font-family: ui-monospace, SFMono-Regular, Menlo, monospace;
    }

    .post-title {
      font-size: 1.5rem;
      font-weight: 700;
      margin: 0;
      line-height: 1.2;
      color: #f8f8f2;
    }

    .post-tags {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
      margin-top: 1rem;
    }

    .tag {
      font-size: 0.75rem;
      background: #44475a;
      padding: 0.15rem 0.45rem;
      border-radius: 0.25rem;
      color: #6272a4;
      font-family: ui-monospace, SFMono-Regular, Menlo, monospace;
      transition: background 0.15s;
    }

    .tag:hover {
      background: #6272a4;
    }

    .post-tags {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
    }

    .tag {
      font-size: 0.75rem;
      background: #44475a;
      padding: 0.15rem 0.45rem;
      border-radius: 0.25rem;
      color: #6272a4;
      font-family: ui-monospace, SFMono-Regular, Menlo, monospace;
      transition: background 0.15s;
    }

    .tag:hover {
      background: #6272a4;
    }

    /* Post content */
    .post-content {
      font-size: 1rem;
      line-height: 1.6;
      color: #f8f8f2;
    }

    .post-content h2 {
      font-size: 1.2rem;
      font-weight: 600;
      margin: 1.5rem 0 0.8rem 0;
      color: #f8f8f2;
    }

    .post-content h3 {
      font-size: 1rem;
      font-weight: 600;
      margin: 1.2rem 0 0.6rem 0;
      color: #f8f8f2;
    }

    .post-content p {
      margin: 0.8rem 0;
    }

    .post-content ul, .post-content ol {
      margin: 0.8rem 0;
      padding-left: 1.5rem;
    }

    .post-content li {
      margin: 0.3rem 0;
    }

    .post-content a {
      color: #ffb86c;
      text-decoration: underline;
      text-decoration-thickness: 1px;
      text-underline-offset: 2px;
    }

    .post-content a:hover {
      color: #ffa500;
    }

    .post-content code {
      font-family: ui-monospace, SFMono-Regular, Menlo, monospace;
      background: #44475a;
      padding: 0.1rem 0.3rem;
      border-radius: 0.2rem;
      font-size: 0.9em;
    }

    .post-content pre {
      background: #282a36;
      padding: 1rem;
      border-radius: 0.5rem;
      overflow-x: auto;
      margin: 1rem 0;
      border: 1px solid #44475a;
    }

    .post-content pre code {
      background: none;
      padding: 0;
      color: #f8f8f2;
    }

    .post-content blockquote {
      border-left: 4px solid #ffb86c;
      padding-left: 1rem;
      margin: 1rem 0;
      font-style: italic;
      color: #6272a4;
    }

    .post-content img {
      max-width: 100%;
      height: auto;
      border-radius: 0.5rem;
      margin: 1rem 0;
    }

    /* Post footer */
    .post-footer {
      margin-top: 4rem;
      padding-top: 2rem;
      border-top: 1px solid #44475a;
    }

    .post-navigation {
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .nav-link {
      font-size: 0.9rem;
      color: #6272a4;
      transition: color 0.15s;
    }

    .nav-link:hover {
      color: #f8f8f2;
    }

    /* Responsive design */
    @media (max-width: 768px) {
      .container {
        padding: 1rem;
      }
      
      .post-title {
        font-size: 1.3rem;
      }
      
      .post-content {
        font-size: 0.9rem;
      }
      
      .post-content h2 {
        font-size: 1.1rem;
      }
      
      .post-content h3 {
        font-size: 0.95rem;
      }
      
      .post-navigation {
        flex-direction: column;
        gap: 1rem;
        align-items: flex-start;
      }
      
      .post-meta {
        flex-direction: column;
        align-items: flex-start;
        gap: 0.5rem;
      }
    }
  </style>
</head>

<body>
  <div class="container">
    <nav>
      <a href="../../index.html" class="back-link">← Back to Home</a>
    </nav>
    
    <article class="blog-post">
      <header class="post-header">
        <div class="post-meta">
          <span class="post-date">10th July 2025</span>
          <span class="post-status">Get Rekt</span>
        </div>
        <h1 class="post-title">How to make an LLM play Black Myth: Wukong</h1>
        <div class="post-tags">
          <span class="tag">AI</span>
          <span class="tag">gaming</span>
          <span class="tag">LLM</span>
          <span class="tag">automation</span>
        </div>
      </header>

      <div class="post-content">
        <h2>What did I build?</h2>

        <div style="margin: 1rem 0;">
          <video controls style="width: 100%; border-radius: 0.5rem; margin-bottom: 0.3rem;">
            <source src="assets/smash.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p style="margin: 0; font-size: 0.9rem; color: #6272a4;">New input paradigm - controlling 3D embodied characters through natural speech.</p>
        </div>

        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin: 1rem 0;">
          <div>
            <video controls style="width: 100%; border-radius: 0.5rem; margin-bottom: 0.3rem;">
              <source src="assets/dodge.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <p style="margin: 0; font-size: 0.9rem; color: #6272a4;">Context awareness - control input (space-bar press for dodging) is fed into the system context - the robot responds accordingly.</p>
          </div>

          <div>
            <video controls style="width: 100%; border-radius: 0.5rem; margin-bottom: 0.3rem;">
              <source src="assets/time.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <p style="margin: 0; font-size: 0.9rem; color: #6272a4;">Spatial + Vision + Time awareness - human like immersion.</p>
          </div>
        </div>

        <div style="display: flex; gap: 1rem; margin: 1rem 0 0.3rem 0;">
          <img src="assets/personality_config.png" alt="Personality Configuration" style="flex: 1; max-width: 50%; border-radius: 0.5rem;">
          <img src="assets/dashboard.png" alt="Dashboard" style="flex: 1; max-width: 50%; border-radius: 0.5rem;">
        </div>

        <p style="margin: 0 0 1rem 0; font-size: 0.9rem; color: #6272a4;">Personality + characteristics + speech styles can be tailored.</p>

        <p style="margin: 1rem 0; font-size: 0.9rem; color: #6272a4;">
          Mod: <a href="https://www.ready.mp/" target="_blank" style="color: #ffb86c;">ready.mp</a> • 
          Engine: <a href="http://wukong.egoai.com" target="_blank" style="color: #ffb86c;">wukong.egoai.com</a>
          <span style="color: #6272a4; font-size: 0.8rem;"> (availability uncertain)</span>
        </p>


        <h2>How did I build it?</h2>

        <p>The number 1 problem you will run into while building something like this is - Latency. Ideal total latency for video games: 20–60 ms  (that pretty FAST <img src="assets/sonic-running.gif" alt="Sonic Running" style="height: 1.2em; vertical-align: middle;">). However average latency for LLMs is 6 seconds (anecdotally  <img src="assets/slow_parrot.gif" alt="Sonic Running" style="height: 0.9em; vertical-align: middle;">).</p>

        <img src="assets/latency_chart.png" alt="Latency Chart" style="max-width: 100%; border-radius: 0.5rem; margin: 1rem 0;">

        <p>No one wants to see an autistic alien use the joystick at turtle speeds <img src="assets/this_is_fine.gif" alt="this_is_fine" style="height: 1.3em; vertical-align: middle;">.</p>

        <div style="display: flex; justify-content: center; margin: 1rem 0;">
          <img src="assets/no_brain.jpg" alt="No Brain" style="max-width: 100%; border-radius: 0.5rem; margin: 1rem 0;">
        </div>

        <p>Computer controlled game experiences are still in their early stages, there have been a <a href="https://github.com/BAAI-Agents/Cradle" target="_blank">few</a> great attempts, but latency and LLM agency is a long way out.</p>

        <h3>Can you engineer your way through this?</h3>

        <p>Short answer <span style="color: #bd93f9;">Yes</span>. Here is how:</p>

        <img src="assets/flowchart.png" alt="Flowchart" style="max-width: 100%; border-radius: 0.5rem; margin: 1rem 0;">

        <p>The <span style="color: #bd93f9">fundamental difference</span> in my approach here is to write game scripts (pre-meditated or generated by LLM on the fly) for controlling the agent input.</p>
        <p> <img src="assets/catjam.gif" alt="No Brain" style="height: 1.1em; vertical-align: middle;"> LLMs never controls the control input directly. LLM only decides what game script to run. The scripts are then injected in the game engine and executed in realtime.</p>

        <p>This approach is inspired from <a href="https://github.com/MineDojo/Voyager" target="_blank">Voyager</a> from Minecraft. This is where I see the industry heading in the short to mid term.</p>

        <p>Example of how I implemented this approach in Wukong:</p>

        <pre><code>
  system_prompt: |
  You are co-op playing Wukong video game with the user: 

  Here is your personality:
  {personality:}

  The user is asking you to perform an action.

  Here is the user message:
  {user_message:}

  Analyze the user message and classify it into one of these action types:
  1. combat: Combat or attacking actions
  2. spells: Casting or using spells
  3. transform: Transformation or changing form
  4. unsupported: Any action that doesn't fit the above categories

  You must respond with 'action_type' field with one of these values.
  - "combat"
  - "spells"
  - "transform"
  - "unsupported"
        </code></pre>

        <p>You see how the LLM is only ever deciding what action to perform. It is never actually trying to perform the action in real-time using computer control. It just returns the "action-string".</p>

        <p>Action execution is handled by game-scripts that are executed inside the game engine (unreal or unity) based on the "action-string" it receives from the LLM.</p>

        <p>I know some of you are going to be like - <span style="color: #bd93f9">ACKHYUALLY</span> - that is not the LLM playing the game.</p>

        <div style="display: flex; justify-content: center; margin: 1rem 0;">
          <img src="assets/actually.png" alt="Actually" style="max-width: 100%; border-radius: 0.5rem; margin: 1rem 0;">
        </div>

        <p>But I would like to argue - I am using LLMs for what they are <span style="color: #bd93f9">ACKHYUALLY</span> good at - <strong>REASONING</strong>.</p>

        <p><strong>AND</strong></p>

        <p>I am using the game engine for it is <span style="color: #bd93f9">ACKHYUALLY</span> good at - <strong>CONTROL INPUT</strong>.</p>

        <p>I know some of you are thinking - this is not a generalizable approach. You will need to pre-meditate game scripts for all possible items in the "action-space" for each game (lotta manual labor).</p>

        <p>Well that is where having the LLM generate game scripts on the fly comes into play. Voyager has achieved great success at that with Minecraft.</p>

        <video controls style="max-width: 100%; border-radius: 0.5rem; margin: 1rem 0;">
          <source src="assets/voyager.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>

        <h3>Optimizations</h3>

        <div style="display: flex; justify-content: center; margin: 1rem 0;">
          <img src="assets/optimization.jpg" alt="Yo Dawg Optimization Meme" style="max-width: 100%; border-radius: 0.5rem;">
        </div>

        <p>6 seconds is still however a lot of latency - even if the LLM is just generating the "action-string". There are other modules such as TTS/STT, Game Vision + Game Log ingestion, RAG, script injection etc that might add more latency on top of the LLM.</p>

        <div style="border-bottom: 1px solid #44475a; margin: 2rem 0;"></div>

        <p>The number 1 unlock here is to <strong>parallelize your game input ingestion pipeline</strong>. As you will notice in the above diagram, the vision and log ingestion are a non blocking operation for User action/dialogue requests.</p>

        <p>One drawback - the LLM's context can lag 10 seconds (talks about killing a monster, when you have moved on to the next stage).</p>

        <div style="border-bottom: 1px solid #44475a; margin: 2rem 0;"></div>

        <p>Another unlock is to <strong>reduce input tokens</strong>. Have the LLM summarize the vision/logs into text summary. This will reduce cost and latency for all future LLM calls.</p>

        <pre><code>system_prompt: |
  You are analyzing {NAME_OF_THE_GAME:} game.
  The description of the game is as follows: {DESCRIPTION_OF_THE_GAME:}
  The plot of the game is as follows: {PLOT_OF_THE_GAME:}
  The game context data is as follows: {GAME_CONTEXT_DATA:}

  Your task is to analyze the game vision and provide a summary of what the user is seeing.

  Here is what the user is seeing in the game:</code></pre>

        <div style="border-bottom: 1px solid #44475a; margin: 2rem 0;"></div>

        <p>Another interesting concept I have recently learned is called <a href="https://www.reddit.com/r/OpenAI/comments/1l70htm/the_23_solution_why_running_redundant_llms_is/" target="_blank">LLM Drag-Racing</a> - beware - its expensive</p>

        <p>The crux of the concept is LLM are often faster than 6 seconds latency but they are un-reliable in doing so. What if we could make LLM calls to 5 different providers and use the one with fastest response, and do this for every call. On average you will end up with much lower overall latency.</p>

        <div style="border-bottom: 1px solid #44475a; margin: 2rem 0;"></div>

        <p>Another big latency add-on is <strong>Text to Speech (TTS) and Speech to Text (STT) API calls</strong>. They each add around 3 seconds to the latency (depending on text length).</p>

        <p>The best work around here is to use <a href="https://platform.openai.com/docs/guides/realtime" target="_blank">Real Time APIs</a>.</p>

        <p>These APIs require you to establish a websocket connection directly with the server hosting these LLMs. Additionally, the input and output are streamed in audio/text chunks. So you can start relaying that audio/text chunks to the user as you receive them.</p>

        <p>Additionally, these APIs are capable of accepting audio input directly (no need to perform STT), and also audio output directly (no TTS required).</p>

        <p>The limitation with these APIs is that they are heavily censored. For example: instructing wukong to go kill the monster wolf can be flagged as policy violation.</p>

        <div style="border-bottom: 1px solid #44475a; margin: 2rem 0;"></div>

        <p>I will keep adding more insights about building agentic infrastructure as I come across them.</p>
      </div>

      <footer class="post-footer">
        <div class="post-navigation">
          <a href="../../index.html" class="nav-link">← Back to Home</a>
        </div>
      </footer>
    </article>
  </div>
</body>

</html> 